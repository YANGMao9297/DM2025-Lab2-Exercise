{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a decoding expert skilled at converting sequences of phonemes into English words and, in order, either attempting to form sentences or preserving the original words.\"\\\n",
    "        \"Based on the received phoneme sequence, you first generate three possible sentences and then select the best one as the final output.\" \\\n",
    "        \"The phoneme sequence includes the following types, and the symbol ' | ' represents a space. PHONEME = ['BLANK','AA', 'AE', 'AH', 'AO', 'AW','AY', 'B',  'CH', 'D', 'DH','EH', 'ER', 'EY', 'F', 'G','HH', 'IH', 'IY', 'JH', 'K','L', 'M', 'N', 'NG', 'OW','OY', 'P', 'R', 'S', 'SH','T', 'TH', 'UH', 'UW', 'V','W', 'Y', 'Z', 'ZH',' | ',]\"\\\n",
    "        \"Only output the sentence that best matches the original phonemes and all punctuation marks should be removed.\"\n",
    "        \"Input: a list of phoneme sequences. Output: a list of strings\"\\\n",
    "        \"- Remove all punctuation marks, keeping only apostrophes. -all lowercase.\"\\\n",
    "        \"- Example:\"\\\n",
    "        \"Input: B R IH NG  |  IH T  |  K L OW S ER  | \"\\\n",
    "        \"Output: bring it closer\"\n",
    "        \"- Only output a list of strings. Ensure the sentences exactly correspond to the phonemes.\"\\\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"D:/ybcvx/Documents/NCKU/ISA5810/Lab2/brain-to-text/config_genai/.env\" ##改成放API的路徑\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred when generating response, error: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>block</th>\n",
       "      <th>trial</th>\n",
       "      <th>phonemes</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>t15.2024.07.19</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>DH AH  |  S AH M P R IY M  |  K AO R T  |  W A...</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session  block  trial  \\\n",
       "1168  t15.2024.07.19     10     40   \n",
       "\n",
       "                                               phonemes    id  \n",
       "1168  DH AH  |  S AH M P R IY M  |  K AO R T  |  W A...  1168  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "\n",
    "predict_df = pd.read_csv(\"phoneme_rnn.csv\")\n",
    "predict_df['id'] = range(len(predict_df))\n",
    "predict_df = predict_df[1168:1169]  #改成你要的範圍\n",
    "print(len(predict_df))\n",
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_list = predict_df['phonemes'].to_list()\n",
    "len(predict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class best_ans(BaseModel):\n",
    "    sentence_1: str\n",
    "    sentence_2: str\n",
    "    sentence_3: str\n",
    "    sentence_4: str\n",
    "    sentence_5: str\n",
    "    best: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OK: Pong!\n"
     ]
    }
   ],
   "source": [
    "# 打一個「最小請求」測試\n",
    "from google import genai\n",
    "client = genai.Client(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "try:\n",
    "    r = client.models.generate_content(model=\"gemini-2.5-flash\", contents=[\"ping\"])\n",
    "    print(\"✅ OK:\", r.text[:60])\n",
    "except Exception as e:\n",
    "    print(\"❌ ERR:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_labels = []\n",
    "\n",
    "for i, prompt in enumerate(predict_list):\n",
    "    text_response = prompt_gemini(\n",
    "        input_prompt=prompt,\n",
    "        schema=list[best_ans],\n",
    "        temperature=0.0,\n",
    "        system_instruction=SYSTEM_INSTRUCTION\n",
    "    )\n",
    "\n",
    "    if not text_response:\n",
    "        pred_labels.append(\"\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        structured_resp = json.loads(text_response)\n",
    "        bests = [resp.get(\"best\", \"\") for resp in structured_resp]\n",
    "        if not bests:\n",
    "            pred_labels.append(\"\")\n",
    "        else:\n",
    "            pred_labels.extend(bests)\n",
    "    except Exception as e:\n",
    "        print(f\"JSON parsing failed at index {i}: {e}\")\n",
    "        pred_labels.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the supreme court war be a decision today']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    \"id\": predict_df['id'],\n",
    "    \"text\": pred_labels\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"result.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"result.csv\")\n",
    "df2 = pd.read_csv(\"predict.csv\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(\"result.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dm2025-lab2-exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
